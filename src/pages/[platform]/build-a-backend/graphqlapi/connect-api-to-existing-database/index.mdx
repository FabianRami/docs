import { getCustomStaticPath } from '@/utils/getCustomStaticPath';

export const meta = {
  title: 'Connect your API to an existing database',
  description:
    'Learn how to connect your API to an existing MySQL or PostgreSQL database.',
    platforms: ['javascript', 'react-native', 'flutter', 'swift', 'android']

};

export const getStaticPaths = async () => {
  return getCustomStaticPath(meta.platforms);
};

export function getStaticProps(context) {
  return {
    props: {
      platform: context.params.platform,
      meta
    }
  };
}

<InlineFilter filters={['javascript', 'react-native', 'flutter', 'swift', 'android']}>

In this section, you'll learn how to:

- Connect to an existing MySQL or PostgreSQL database
- Generate and make preserved changes to the generated GraphQL schema
- Execute SQL statements with custom GraphQL queries and mutations using the new `@sql` directive
- Deploy an AWS AppSync GraphQL API.

## Connect your API with an existing MySQL or PostgreSQL database

<BlockSwitcher>
<Block name="Amplify CLI">

Pre-requisites:

- Have an existing MySQL or PostgreSQL database deployed
- The [Amplify CLI is installed and configured](/cli/start/install/)
- Have an Amplify [project already initialized](/cli/start/workflows/#initialize-new-project)

Amplify CLI supports connecting to any existing MySQL or PostgreSQL database.

<Accordion title="Configure VPC settings for your database" headingLevel="3" eyebrow="Learn more">

If your database exists within a VPC, the RDS instance must be configured to be `Publicly accessible`. This does not mean the instance needs to accessible from the internet.

When importing a database schema, the Amplify CLI will automatically discover that the RDS instance is in a VPC and install a Lambda function into that VPC, subnets, and security groups.

The target security group(s) must have two inbound rules set up:

- A rule allowing traffic on port 443 from the security group.

- An inbound rule allowing traffic on the database port from the security group. (Default: 3306 for MySQL. 5432 for PostgreSQL.)

<Callout>
  **NOTE:** Make sure to limit the type of inbound traffic your security group
  allows according to your security needs and/or use cases. For information on
  security group rules, please refer to the Amazon EC2 documentation:
  https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/security-group-rules-reference.html?icmpid=docs_ec2_console
</Callout>

</Accordion>

First, set up your GraphQL API by running:

```sh
amplify import api
```

Answer the prompts with your database connection details:

```console
? Here is the GraphQL API that we will create. Select a setting to edit or continue:
  > Continue
? Select the database type:
  > MySQL // or PostgreSQL
Please provide the following database connection information:
? Enter the database url or host name:
  > <host>
? Enter the port number:
  > 3306
? Enter the username:
  > <username>
? Enter the password:
  > <password>
? Enter the database name:
  > <database>
```

Upon successfully connecting, the Amplify CLI will fetch the database schema and import it by generating an Amplify GraphQL schema from it into `/amplify/backend/api/<api-name>/schema.sql.graphql`.

<Callout>
  **NOTE:** Only tables that have a primary key will be imported into the
  generated schema.
</Callout>

<Accordion title="Update Secrets" headingLevel="3" eyebrow="Learn more">

If you need to update the credentials used to connect to the database, run the following command:

```sh
amplify api update-secrets
```

This will prompt you to re-enter the database connection details. Once completed, the Amplify CLI will store the updated values in the SSM parameters that the SQL Lambda retrieves to connect to the SQL database.

Test the connection by running:

```sh
amplify api generate-schema
```

The Amplify CLI will attempt to fetch the database schema and regenerate the GraphQL schema in `/amplify/backend/api/<api-name>/schema.sql.graphql`.

</Accordion>

</Block>

<Block name="AWS CDK">

Pre-requisites:

- Have an existing MySQL or PostgreSQL database deployed
- The [AWS CDK CLI is installed](https://docs.aws.amazon.com/cdk/v2/guide/getting_started.html#getting_started_install)
- Have an [AWS CDK application initialized](https://docs.aws.amazon.com/cdk/v2/guide/hello_world.html)

<Accordion title="Configure VPC settings for your database" headingLevel="3" eyebrow="Learn more">

If your database exists within a VPC, the RDS instance must be configured to be `Publicly accessible`. This does not mean the instance needs to accessible from the internet.

When importing a database schema, the Amplify CLI will automatically discover that the RDS instance is in a VPC and install a Lambda function into that VPC, subnets, and security groups.

The target security group(s) must have two inbound rules set up:

- A rule allowing traffic on port 443 from the security group.

- An inbound rule allowing traffic on the database port from the security group. (Default: 3306 for MySQL. 5432 for PostgreSQL.)

<Callout>
  **NOTE:** Make sure to limit the type of inbound traffic your security group
  allows according to your security needs and/or use cases. For information on
  security group rules, please refer to the Amazon EC2 documentation:
  https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/security-group-rules-reference.html?icmpid=docs_ec2_console
</Callout>

</Accordion>

First, install required packages:

```sh
npm install @aws-amplify/graphql-api-construct
```

Open the main stack file in your CDK project (usually located in `lib/<your-project-name>-stack.ts`). Import the necessary constructs at the top of the file:

```ts
import {
  AmplifyGraphqlApi,
  AmplifyGraphqlDefinition
} from '@aws-amplify/graphql-api-construct';
```

Create a `blogs` table in your database:

```sql
CREATE TABLE blogs (
  id      varchar(255)  NOT NULL PRIMARY KEY,
  title   varchar(255)  NOT NULL,
);
```

Execute the following SQL statement on your database using a MySQL, PostgreSQL Client or CLI tool similar to `psql` and export the output to a CSV file:

<Callout>
  **NOTE:** Make sure to include column headers when exporting the output to a
  CSV file.
</Callout>

Replace `<database-name>` with the name of your database/schema.

<BlockSwitcher>
<Block name="MySQL">
```sql
SELECT
  INFORMATION_SCHEMA.COLUMNS.TABLE_NAME,
  INFORMATION_SCHEMA.COLUMNS.COLUMN_NAME,
  INFORMATION_SCHEMA.COLUMNS.COLUMN_DEFAULT,
  INFORMATION_SCHEMA.COLUMNS.ORDINAL_POSITION,
  INFORMATION_SCHEMA.COLUMNS.DATA_TYPE,
  INFORMATION_SCHEMA.COLUMNS.COLUMN_TYPE,
  INFORMATION_SCHEMA.COLUMNS.IS_NULLABLE,
  INFORMATION_SCHEMA.COLUMNS.CHARACTER_MAXIMUM_LENGTH,
  INFORMATION_SCHEMA.STATISTICS.INDEX_NAME,
  INFORMATION_SCHEMA.STATISTICS.NON_UNIQUE,
  INFORMATION_SCHEMA.STATISTICS.SEQ_IN_INDEX,
  INFORMATION_SCHEMA.STATISTICS.NULLABLE
      FROM INFORMATION_SCHEMA.COLUMNS
      LEFT JOIN INFORMATION_SCHEMA.STATISTICS ON INFORMATION_SCHEMA.COLUMNS.TABLE_NAME=INFORMATION_SCHEMA.STATISTICS.TABLE_NAME AND INFORMATION_SCHEMA.COLUMNS.COLUMN_NAME=INFORMATION_SCHEMA.STATISTICS.COLUMN_NAME
      WHERE INFORMATION_SCHEMA.COLUMNS.TABLE_SCHEMA = '<database-name>';
```
</Block>
<Block name="PostgreSQL">
```sql
SELECT enum_name,
       enum_values,
       table_name,
       column_name,
       column_default,
       ordinal_position,
       data_type,
       udt_name,
       is_nullable,
       character_maximum_length,
       indexname,
       REPLACE(Substring(indexdef FROM '\((.*)\)'), '"', '') AS index_columns
FROM   information_schema.columns
       LEFT JOIN pg_indexes
              ON information_schema.columns.table_name = pg_indexes.tablename
                 AND information_schema.columns.column_name = any (
                     String_to_array(
                     REPLACE(Substring
                     (indexdef FROM '\((.*)\)'), '"', ''), ', ') )
       LEFT JOIN (SELECT t.typname              AS enum_name,
                         Array_agg(e.enumlabel) AS enum_values
                  FROM   pg_type t
                         JOIN pg_enum e
                           ON t.oid = e.enumtypid
                         JOIN pg_catalog.pg_namespace n
                           ON n.oid = t.typnamespace
                  WHERE  n.nspname = 'public'
                  GROUP  BY enum_name) enums
              ON enums.enum_name = information_schema.columns.udt_name
WHERE  table_schema = 'public'
       AND table_catalog = '<database-name>'
```
</Block>
</BlockSwitcher>

Generate an Amplify GraphQL API schema by running the following command, replacing the `--sql-schema` value with the path to the CSV file created in the previous step:

```sh
npx @aws-amplify/cli api generate-schema --sql-schema <path-to-schema.csv> --engine-type mysql --out schema.sql.graphql
```

In the main stack class, add the following code to define a new GraphQL API. Replace `stack` with the name of your stack instance and update the path to the `schema.sql.graphql` file generated in the previous step:

```ts
new AmplifyGraphqlApi(stack, 'SqlBoundApi', {
  apiName: 'MySqlBoundApi',
  definition: AmplifyGraphqlDefinition.fromFilesAndDefinition(
    [path.join(__dirname, 'schema.sql.graphql')],
    {
      strategy: {
        dbType: 'MYSQL',
        vpcConfiguration: {
          vpcId: 'vpc-123456',
          securityGroupIds: ['sg-123', 'sg-456'],
          subnetAvailabilityZoneConfig: [
            { subnetId: 'sn-123456', availabilityZone: 'us-east-1a' },
            { subnetId: 'sn-987654', availabilityZone: 'us-east-1b' }
          ]
        },
        dbConnectionConfig: {
          hostnameSsmPath:
            '/path/to/ssm/SecretString/containing/value/of/hostname',
          portSsmPath: '/path/to/ssm/SecretString/containing/value/of/port',
          usernameSsmPath:
            '/path/to/ssm/SecretString/containing/value/of/username',
          passwordSsmPath:
            '/path/to/ssm/SecretString/containing/value/of/password',
          databaseNameSsmPath:
            '/path/to/ssm/SecretString/containing/value/of/databaseName'
        }
      }
    }
  ),
  authorizationModes: {
    apiKeyConfig: { expires: Duration.days(7) }
  },
  translationBehavior: {
    sandboxModeEnabled: true
  }
});
```

The API will have an API key enabled for authorization. Sandbox mode is enabled for testing.

Before deploying, make sure to:

- Change the `dbType` to match your database engine of either MySQL or PostgreSQL.

- Update the `vpcId`, `securityGroupIds`, and `subnetAvailabilityZoneConfig` with your vpc details.

- Update the SSM parameter paths within `dbConnectionConfig` to point to those existing in your AWS account.

</Block>
</BlockSwitcher>

<Accordion title="RDS Proxy for improved connectivity" headingLevel="3" eyebrow="Learn more">

Consider adding an RDS Proxy in front of the cluster to manage database connections.

When using AWS AppSync with a relational database like Amazon RDS, each query from your application needs to open a separate connection to the database.

If there are a large number of queries occurring concurrently, it can exceed the connection limit on the database and result in errors like "Too many connections". To avoid this, the Amplify CLI can use an RDS Proxy when connecting your AppSync API to a database.

The RDS Proxy acts as an intermediary sitting in front of your database. Instead of each application query opening a direct connection to the database, they will connect through the Proxy. The Proxy helps manage and pool these connections to avoid overwhelming your database cluster. This improves the availability of your API, allowing more queries to execute concurrently without hitting connection limits.

However, there is a tradeoff of increased latency - queries may take slightly longer as they wait for an available connection from the Proxy pool. There are also additional costs associated with using RDS Proxy. Please refer to the [pricing page for RDS Proxy](https://aws.amazon.com/rds/proxy/pricing/) to learn more.

</Accordion>

## Apply authorization rules on the models

The `@auth` directive can be used to restrict access to data and operations by specifying authorization rules. It allows granular access control over the GraphQL API based on the user's identity and attributes.

All model level authorization rules are supported for Amplify GraphQL schemas generated from MySQL and PostgreSQL databases.

<Callout>**NOTE:** Field level auth rules are not supported.</Callout>

In the example below, public users authorized via API Key are granted unrestricted access to all posts.

Add the following auth rule to the `Blog` model within the `schema.sql.graphql` file:

```graphql
type Blog @model @refersTo(name: "blogs") @auth(rules: [{ allow: public }]) {
  id: String! @primaryKey
  title: String!
}
```

In a real world scenario, you can instead define auth rules that only allow public users to read posts, and authenticated users the ability to update or delete their posts.

For more information on each rule please refer to our documentation on [Authorization rules](/[platform]/build-a-backend/graphqlapi/customize-authorization-rules/).

## Deploy your API

<BlockSwitcher>
<Block name="Amplify CLI">
To deploy the API, you can use the `amplify push` command:

```sh
amplify push
```

```console
? Are you sure you want to continue? Y
? Do you want to generate code for your newly created GraphQL API? Y
? Choose the code generation language target: javascript (or your preferred language target)
? Enter the file name pattern of graphql queries, mutations and subscriptions src/graphql/**/*.js
? Do you want to generate/update all possible GraphQL operations - queries, mutations and subscriptions? Y
? Enter maximum statement depth [increase from default if your schema is deeply nested]: 2
```

</Block>
<Block name="AWS CDK">
To deploy the API, you can use the `cdk deploy` command:

```sh
cdk deploy
```

</Block>
</BlockSwitcher>

Now the API has been deployed and you can start using it!

You can start querying from the AWS AppSync console or integrate it into your application using the AWS Amplify libraries!

## Apply iterative changes from the database definition

<Accordion
  title="Mapping of SQL Data Types to GraphQL Types"
  headingLevel="3"
  eyebrow="Info"
>
<Callout>

**Note:** MySQL does not support time zone offsets in date time or timestamp fields. Instead, we will convert these values to `datetime`, without the offset.

Unlike MySQL, PostgreSQL does support date time or timestamp values with an offset.

</Callout>
| SQL                | GraphQL      |
|--------------------|--------------|
| **String**         |              |
| char               | <span style={{ color: "orange" }}>String</span>       |
| varchar            | <span style={{ color: "orange" }}>String</span>       |
| tinytext           | <span style={{ color: "orange" }}>String</span>       |
| text               | <span style={{ color: "orange" }}>String</span>       |
| mediumtext         | <span style={{ color: "orange" }}>String</span>       |
| longtext           | <span style={{ color: "orange" }}>String</span>       |
| **Geometry**       |              |
| geometry           | <span style={{ color: "orange" }}>String</span>       |
| point              | <span style={{ color: "orange" }}>String</span>       |
| linestring         | <span style={{ color: "orange" }}>String</span>       |
| geometryCollection | <span style={{ color: "orange" }}>String</span>       |
| **Numeric**        |              |
| smallint           | <span style={{ color: "skyblue" }}>Int</span>          |
| mediumint          | <span style={{ color: "skyblue" }}>Int</span>          |
| int                | <span style={{ color: "skyblue" }}>Int</span>          |
| integer            | <span style={{ color: "skyblue" }}>Int</span>          |
| bigint             | <span style={{ color: "skyblue" }}>Int</span>          |
| tinyint            | <span style={{ color: "skyblue" }}>Int</span>          |
| float              | <span style={{ color: "blue" }}>Float</span>        |
| double             | <span style={{ color: "blue" }}>Float</span>        |
| decimal            | <span style={{ color: "blue" }}>Float</span>        |
| dec                | <span style={{ color: "blue" }}>Float</span>        |
| numeric            | <span style={{ color: "blue" }}>Float</span>        |
| **Date and Time**  |              |
| date               | <span style={{ color: "firebrick" }}>AWSDate</span>      |
| datetime           | <span style={{ color: "red" }}>AWSDateTime</span>   |
| timestamp          | <span style={{ color: "red" }}>AWSDateTime</span>   |
| time               | <span style={{ color: "deeppink" }}>AWSTime</span>       |
| year               | <span style={{ color: "skyblue" }}>Int</span>          |
| **Binary**         |              |
| binary             | <span style={{ color: "orange" }}>String</span>        |
| varbinary          | <span style={{ color: "orange" }}>String</span>        |
| tinyblob           | <span style={{ color: "orange" }}>String</span>        |
| blob               | <span style={{ color: "orange" }}>String</span>        |
| mediumblob         | <span style={{ color: "orange" }}>String</span>        |
| longblob           | <span style={{ color: "orange" }}>String</span>        |
| **Others**         |              |
| bool               | <span style={{ color: "green" }}>Boolean</span>       |
| boolean            | <span style={{ color: "green" }}>Boolean</span>       |
| bit                | <span style={{ color: "skyblue" }}>Int</span>          |
| json               | <span style={{ color: "purple" }}>AWSJSON</span>       |
| enum               | <span style={{ color: "violet" }}>ENUM</span>          |

</Accordion>

<BlockSwitcher>
  <Block name="Amplify CLI">

1. Make any adjustments to your SQL statements such as:

```sql
CREATE TABLE posts (
  id              varchar(255)           NOT NULL PRIMARY KEY,
  title           varchar(255)           NOT NULL,
  content         varchar(255)           NOT NULL,
  published       tinyint(1)  DEFAULT 0  NOT NULL
  published_date  date                       NULL
);
```

2. Generate an updated schema:

```sh
amplify api generate-schema
```

<Callout>
  **NOTE:** If the connection to the database fails, the CLI will prompt you to
  retry using a VPC endpoint.
</Callout>

3. Deploy your changes to the cloud:

```sh
amplify push -y
```

</Block>
  <Block name="AWS CDK">
  1. Make any adjustments to your SQL statements such as:

```sql
CREATE TABLE posts (
  id              varchar(255)           NOT NULL PRIMARY KEY,
  title           varchar(255)           NOT NULL,
  content         varchar(255)           NOT NULL,
  published       tinyint(1)  DEFAULT 0  NOT NULL
  published_date  date                       NULL
);
```

2. Run the following SQL statement on your database using a MySQL, PostgreSQL Client or CLI tool similar to `psql`. Export the output to a CSV file with column headers included.

Replace `<database-name>` with the name of your database/schema.

<BlockSwitcher>
<Block name="MySQL">
```sql
SELECT information_schema.columns.*,
       information_schema.statistics.index_name,
       information_schema.statistics.non_unique,
       information_schema.statistics.seq_in_index,
       information_schema.statistics.nullable
FROM   information_schema.columns
       LEFT JOIN information_schema.statistics
              ON information_schema.columns.table_name =
                 information_schema.statistics.table_name
                 AND information_schema.columns.column_name =
                     information_schema.statistics.column_name
WHERE  information_schema.columns.table_schema = '<database-name>'
```
</Block>
<Block name="PostgreSQL">
```sql
SELECT enum_name,
       enum_values,
       table_name,
       column_name,
       column_default,
       ordinal_position,
       data_type,
       udt_name,
       is_nullable,
       character_maximum_length,
       indexname,
       REPLACE(Substring(indexdef FROM '\((.*)\)'), '"', '') AS index_columns
FROM   information_schema.columns
       LEFT JOIN pg_indexes
              ON information_schema.columns.table_name = pg_indexes.tablename
                 AND information_schema.columns.column_name = any (
                     String_to_array(
                     REPLACE(Substring
                     (indexdef FROM '\((.*)\)'), '"', ''), ', ') )
       LEFT JOIN (SELECT t.typname              AS enum_name,
                         Array_agg(e.enumlabel) AS enum_values
                  FROM   pg_type t
                         JOIN pg_enum e
                           ON t.oid = e.enumtypid
                         JOIN pg_catalog.pg_namespace n
                           ON n.oid = t.typnamespace
                  WHERE  n.nspname = 'public'
                  GROUP  BY enum_name) enums
              ON enums.enum_name = information_schema.columns.udt_name
WHERE  table_schema = 'public'
       AND table_catalog = '<database-name>'
```
</Block>
</BlockSwitcher>

3. Generate an updated schema by running the following command, replacing the `--sql-schema` value with the path to the CSV file created in the previous step:

```sh
npx @aws-amplify/cli api generate-schema --sql-schema <path-to-schema.csv> --engine-type mysql --out schema.sql.graphql
```

4. Deploy your changes to the cloud:

```sh
cdk deploy
```

</Block>
</BlockSwitcher>

<Accordion title="Supported Directives" headingLevel="3" eyebrow="Info">
| Name         | Supported | Model Level | Field Level | Preserved | Description |
|--------------|:---------:|:-----------:|:-----------:|:---------:|-------------|
| `@model`     | ✅        | ✅          | ❌          | ✅        | Creates a datasource and resolver for a table.            |
| `@auth`      | ✅        | ✅          | ❌          | ✅        | Allows access to data based on a set of authorization methods and operations. |
| `@primaryKey`| ✅        | ❌          | ✅          | ❌        | Sets a field to be the primary key. |
| `@index`     | ✅        | ❌          | ✅          | ❌        | Defines an index on a table.         |
| `@default`   | ✅        | ❌          | ✅          | ❌        | Sets the default value for a column.         |
| `@hasOne`    | ✅        | ❌          | ✅          | ✅        | Defines a one-way 1:1 relationship from a parent to child model. |
| `@hasMany`   | ✅        | ❌          | ✅          | ✅        | Defines a one-way 1:M relationship between two models, the reference being on the child. |
| `@belongsTo` | ✅        | ❌          | ✅          | ✅        | Defines bi-directional relationship with the parent model. |
| `@manyToMany`| ❌        | ❌          | ❌          | ❌        | Defines a M:N relationship between two models.       |
| `@refersTo`  | ✅        | ✅          | ✅          | ✅        | Maps a model to a table, or a field to a column, by name. |
| `@mapsTo`    | ❌        | ❌          | ❌          | ❌        | Maps a model to a DynamoDB table.        |
| `@sql`       | ✅        | ❌          | ✅          | ✅        | Accepts an inline SQL statement or reference to a .sql file to be executed to resolve a Custom Query or Mutation. |

</Accordion>

### Rename & map models to tables

To rename models and fields, you can use the `@refersTo` directive to map the models in the GraphQL schema to the corresponding table or field by name.

By default, the Amplify CLI singularizes each model name using PascalCase and field names that are either snake_case or kebab-case will be converted to camelCase.

In the example below, the Post model in the GraphQL schema is now mapped to the posts table in the database schema. Also, the isPublished is now mapped to the published column on the posts table.

```graphql
type Post @refersTo(name: "posts") @model {
  id: String! @primaryKey
  title: String!
  content: String!
  isPublished: Boolean @refersTo(name: "is-published")
  publishedDate: AWSDate @refersTo(name: "published_date")
}
```

## Create custom queries and mutations

Amplify GraphQL API for SQL databases introduces the `@sql` directive, which allows you to define SQL statements in custom GraphQL queries and mutations. This provides more flexibility when the default, auto-generated GraphQL queries and mutations are not sufficient.

There are two ways to specify the SQL statement - inline or by referencing a `.sql` file.

**Inline SQL Statement**

You can embed the SQL statement directly in the schema using the `statement` argument.

The SQL statement can use parameters in the format `:variable`, which will be bound to the input variables passed when executing a custom GraphQL query or mutation.

In the example below, a SQL statement is defined, accepting a `searchTerm` input variable.

```graphql
type Query {
  searchPosts(searchTerm: String): [Post]
    @sql(statement: "SELECT * FROM posts WHERE title LIKE :searchTerm;")
}
```

{/* TODO: Add a NOTE: about proxy/connection pinning here. */}

**SQL File Reference**

For longer, more complex SQL queries, you can specify the statement in a separate `.sql` file rather than inline. Referencing a file keeps your schema clean and allows reuse of SQL statements across fields.

The reference value must match the name of a `.sql` file located in the `amplify/backend/api/<api-name>/sql-statements` folder.

In the example below, a `getPublishedPostsByDateRange.sql` file containing a SQL statement is being referenced.

```sql
-- getPublishedPostsByRange.sql
SELECT p.id, p.title, p.content, p.published_date
FROM posts p
WHERE p.published = 1
  AND p.published_date > :startDate
  AND p.published_date < :endDate
ORDER BY p.published_date DESC
LIMIT 10
```

```graphql
type Query {
  getPublishedPostsByDateRange(startDate: AWSDate, endDate: AWSDate): [Post]
    @sql(reference: "getPublishedPostsByDateRange")
}
```

The SQL statement will be executed as if it were defined inline in the schema. The same rules apply in terms of using parameters, ensuring valid SQL syntax, and matching the return type to row data.

### Custom Query

```graphql
type Query {
  searchPostsByTitle(title: String): [Post]
    @sql(
      statement: "SELECT * FROM Post WHERE title LIKE CONCAT('%', :title, '%');"
    )
}
```

### Custom Mutation

```graphql
type Mutation {
  publishPostById(id: ID!): AWSJSON
    @sql(statement: "UPDATE posts SET published = :published WHERE id = :id;")
}
```

### Returning row data from custom mutations

SQL statements such as `INSERT`, `UPDATE` and `DELETE` return the number of rows affected.

If you want to return the result of the SQL statement, you can use `AWSJSON` as the return type.

```graphql
type Mutation {
  publishPosts: AWSJSON @sql(statement: "UPDATE Post SET published = 1;")
}
```

This will return a JSON response similar to this:

```json
{
  "data": {
    "publishPosts": "{\"fieldCount\":0,\"affectedRows\":7,\"insertId\":0,\"info\":\"Rows matched: 7  Changed: 7  Warnings: 0\",\"serverStatus\":34,\"warningStatus\":0,\"changedRows\":7}"
  }
}
```

However, you might want to return the actual row data instead.

<BlockSwitcher>
<Block name="MySQL">

In MySQL, you can create and call a stored procedure that performs both an UPDATE statement and SELECT query to return a single post.

Create a stored procedure:

```sql
CREATE PROCEDURE publish_post (IN postId VARCHAR(255))

BEGIN
UPDATE posts SET published = 1 WHERE id = postId;

SELECT * FROM posts WHERE id = postId LIMIT 1;
END
```

Call the stored procedure from the custom mutation:

```graphql
type Mutation {
  publishPostById(id: String!): [Post]
    @sql(statement: "CALL publish_post(:id);")
}
```

<Callout>
  **NOTE:** Unlike the Amplify CLI-generated mutations that return a single
  item, the return type for custom queries and mutations expecting row data must
  be an array of the corresponding model.
</Callout>

</Block>
<Block name="PostgreSQL">

In PostgreSQL, you can add a `RETURNING` clause to an `INSERT`, `UPDATE`, or `DELETE` statement and get the actual modified row data.

Example:

```graphql
type Mutation {
  publishPostById(id: String!): [Post]
    @sql(statement: "UPDATE posts SET price = :id RETURNING *;")
}
```

</Block>
</BlockSwitcher>

## Create relationships between models

You can use the `@hasOne`, `@hasMany`, and `@belongsTo` relational directives to create relationships between models. The field named in the `references` parameter of the relational directives must exist on the child model.

### Has One relationship

Create a one-directional one-to-one relationship between two models using the `@hasOne` directive.

In the example below, a User has a single Profile.

```graphql
type User
  @refersTo(name: "users")
  @model
  @auth(rules: [{ allow: owner }, { allow: groups, groups: ["Admin"] }]) {
  id: String! @primaryKey
  name: String!
  owner: String
  profile: Profile @hasOne(references: ["userId"])
}
```

### Has Many relationship

Create a one-directional one-to-many relationship between two models using the `@hasMany` directive.

In the example below, a Blog has many Posts.

```graphql
type Blog @model {
  id: String! @primaryKey
  title: String!
  posts: [Post] @hasMany(references: ["blogId"])
}

type Post @model {
  id: String! @primaryKey
  title: String!
  content: String!
}
```

### Belongs To relationship

Make a "has one" or "has many" relationship bi-directional with the `@belongsTo` directive.

In the example below, a Post belongs to a Blog.

```graphql
type Post @model {
  id: String! @primaryKey
  title: String!
  content: String!
  blogId: String! @refersTo(name: "blog_id")
  blog: Blog @belongsTo(references: ["blogId"])
}
```

## How does it work?

The Amplify CLI uses AWS Lambda functions to enable features like querying data from your database. To work properly, these Lambda functions need access to common logic and dependencies.

Amplify CLI provides this shared code in the form of Lambda Layers. You can think of Lambda Layers as a package of reusable runtime code that Lambda functions can reference.

When you deploy an Amplify API, it will create two Lambda functions:

### SQL Lambda

This allows you to query and write data to your database from your API.

<Callout>
  **NOTE:** If the database is in a VPC, this Lambda function will be deployed
  in the same VPC as the database. The usage of Amazon Virtual Private Cloud
  (VPC) or VPC peering, with AWS Lambda functions will incur additional charges
  as explained, this comes with an additional cost as explained on the [Amazon
  Elastic Compute Cloud (EC2) on-demand pricing
  page](https://aws.amazon.com/ec2/pricing/on-demand/).
</Callout>

### Updater Lambda

This automatically keeps the SQL Lambda up-to-date by managing its Lambda Layers.

A Lambda layer that includes all the core SQL connection logic lives within the AWS Amplify service account but is executed within your AWS account, when invoked by the SQL Lambda. This allows the Amplify service team to own the ongoing maintenance and security enhancements of the SQL connection logic.

This allows the Amplify team to maintain and enhance the SQL Layer without needing direct access to your Lambdas. If updates to the Layer are needed, the Updater Lambda will receive a signal from Amplify and automatically update the SQL Lambda with the latest Layer.

## Troubleshooting

### Debug Mode

To return the actual SQL error instead of a generic error from AppSync responses, an environment variable `DEBUG_MODE` can be set to `true` on the Amplify CLI-generated `RDSLambdaLogicalID` lambda function.

## Conclusion

Congratulations! You have finished the **Connect your API to an existing database** guide. In this guide, you reviewed connecting to an existing database, making iterative changes to your database schema to ultimately generate and deploy a GraphQL API. You also reviewed which changes and directives are preserved, such as renaming and mapping models to tables, as well as creating custom queries and mutations using inline statements and references to SQL files.

## Next steps

Our recommended next steps include using the API to mutate and query data. You can also review how to subscribe to real-time events to look for mutations in your data. Some resources that will help with this work include:

- [Create, update, and delete application data](/[platform]/build-a-backend/graphqlapi/mutate-data/)
- [Read application data](/[platform]/build-a-backend/graphqlapi/query-data/)
- [Subscribe to real-time events](/[platform]/build-a-backend/graphqlapi/subscribe-data/)

</InlineFilter>
